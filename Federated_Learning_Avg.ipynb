{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWlZlYd092GvFwRgMX04ao",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkim2260/Practice/blob/master/Federated_Learning_Avg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "*   Number of clients: 100 (K=100)  -hyperparameter\n",
        "*   Fraction of sampled clients: 0.1 (C=0.1) -hyperparameter\n",
        "*   Number of rounds: 500 (R = 500)\n",
        "*   Number of local epochs: 10 (E= 10) - hyperparameter\n",
        "*   Mini Batch size: 10 (B=10) - hyperparameter\n",
        "*   Optimizer: torch.optim.SGD\n",
        "*   Criterion: torch.nn.CrossEntropyLoss\n",
        "*   Learning rate: 0.01\n",
        "*   Momentum: 0.9\n",
        "*   Initialization: Xavier\n"
      ],
      "metadata": {
        "id": "dzpuBS7513N5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Client.py"
      ],
      "metadata": {
        "id": "u2aLUiyk6oWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJDr3VPa0VO3"
      },
      "outputs": [],
      "source": [
        "#Federated Averaging(FedAvg)\n",
        "#Reference: Communication-Efficient Learning of Deep Networks for Decentralized Data\n",
        "#multiprocessing of client update and client evaluation.\n",
        "#log tracking: Support tensorboard\n",
        "\n",
        "import gc\n",
        "import pickle\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# 모델을 학습하기 위한 자체(비공개) 데이터 및 리소스가 있는 클라이언트 개체에 대한 클래스\n",
        "# 참여클라이언트에는 일반적으로 다른 클라이언트에 비해 non-iid 자체 데이터 세트\n",
        "#각 클라이언트는 학습된 매겨변수 또는 전역접으로 집계된 매개변수를 사용하여 글로벌 서버와 통신함\n",
        "#속성: 클라이언트의 id를 나타내는 정수 ;#데이터: 로컬 데이터를 포함하는 torch,utils.data.Dataset 인스턴스\n",
        "#device_훈련기계 표시기(예: \"cpu\", \"cuda\") #model:로컬모델로서의 torch.nn 인스턴스\n",
        "    #Attributes:\n",
        "        #id: Integer indicating client's id.\n",
        "        #data: torch.utils.data.Dataset instance containing local data.\n",
        "        #device: Training machine indicator (e.g. \"cpu\", \"cuda\").\n",
        "        #__model: torch.nn instance as a local model.\n",
        "    #\"\"\"\n",
        "class Client(object):\n",
        "\n",
        "   def __init__(self, client_id, local_data, device):\n",
        "     #클라이언트 개체는 센터 서버에 의해 시작됨\n",
        "       self.id = client_id\n",
        "       self.data = local_data\n",
        "       self.device = device\n",
        "       self.__model = None\n",
        "\n",
        "    @property #특성\n",
        "    def model(self):\n",
        "      #매개변수 집계를 위한 로컬 모델 getter\n",
        "        return self.__model\n",
        "    \n",
        "    @model.setter\n",
        "    def model(self, model):\n",
        "    #전역적으로 집계뙨 모델 매개변수를 전달하기 위한 로컬 모델 setter\n",
        "        self.__model = model\n",
        "\n",
        "    def __len__(self):\n",
        "    #클라이언트 로컬 데이터의 총 크기를 반환함\n",
        "        return len(self.data)\n",
        "\n",
        "    def setup(self, **client_config):\n",
        "    #각 클라이언트의 공통 구성을 설정함; 센터 서버에서 호출함\n",
        "        self.dataloader = DataLoader(self.data, batch_size=client_config[\"batch_size\"], shuffle=True)\n",
        "        self.local_epoch = client_config[\"num_local_epochs\"]\n",
        "        self.criterion = client_config[\"criterion\"]\n",
        "        self.optimizer = client_config[\"optimizer\"]\n",
        "        self.optim_config = client_config[\"optim_config\"]\n",
        "\n",
        "    def client_update(self):\n",
        "    #로컬 데이터셋을 사용하여 로컬 모델을 업데이트함\n",
        "        self.model.train()\n",
        "        self.model.to(self,device)\n",
        "\n",
        "        optimizer = eval(self.optimizer)(self.model.parameters(), **self.optim_config)\n",
        "        for e in range(self.local_epoch):\n",
        "            for data, labels in self.dataloader:\n",
        "                data, labels = data.float().to(self.device), labels.long().to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(data)\n",
        "                loss = eval(self.criterion)()(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                if self.device == \"cuda\": torch.cuda.empty_cache()\n",
        "        self.model.to(\"cpu\")\n",
        "\n",
        "    def client_evaluate(self):\n",
        "    # 로컬 데이터 세트를 사용하여 로컬 모델을 평가함(편의상 훈련세트와 동일함) \n",
        "        self.model.eval()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        test_loss, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data, labels in self.dataloader:\n",
        "                data, labels = data.float().to(self_device), labels.long().to(self.device)\n",
        "                outputs = self.model(data)\n",
        "                test_loss += eval(self.criterion)()(outputs, lables).item()\n",
        "\n",
        "                predicted = outputs.argmax(dim=1. keepdim=True)\n",
        "                correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "\n",
        "                if self.device == \"cuda\": torch.cuda.empty_cache()\n",
        "        self.model.to(\"cpu\")\n",
        "\n",
        "        test_loss = test_loss / len(self.dataloader)\n",
        "        test_accuracy = correct / len(self.data)\n",
        "\n",
        "        message = f\"\\t[Client {str(self.id).zfill(4)}]...finished evaluation!\\\n",
        "            \\n\\t=> Test loss: {test_loss:.4f}\\\n",
        "            \\n\\t=> Test accuracy: {100. * test_accuracy:.2f}%\\n\"\n",
        "        print(message, flush=True); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "        return test_loss, test_accuracy\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#################################\n",
        "# Models for federated learning #\n",
        "#################################\n",
        "# McMahan et al., 2016; 199,210 parameters\n",
        "\n",
        "class TwoNN(nn.Module):\n",
        "    def __init__(self, name, in_features, num_hiddens, num_classes):\n",
        "        super(TwoNN, self).__init__()\n",
        "        self.name = name\n",
        "        self.activation = nn.ReLU(True)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=in_features, out_features=num_hiddens, bias=True)\n",
        "        self.fc2 = nn.Linear(in_features=num_hiddens, out_features=num_hiddens, bias=True)\n",
        "        self.fc3 = nn.Linear(in_features=num_hiddens, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.ndim == 4:\n",
        "            x = x.view(x.size(0), -1)  ##무슨의미?\n",
        "        \n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# McMahan et al., 2016; 1,663,370 parameters\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, name, in_channels, hidden_channels, num_hiddens, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.name = name\n",
        "        self.activation = nn.ReLU(True)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=hidden_channels,\n",
        "                               kernel_size=(5,5), padding=1, stride=1, bias = False)\n",
        "        self.conv2 = nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels*2,\n",
        "                               kernel_size=(5,5), padding=1, stride=1, bias= False)\n",
        "        \n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2,2), padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2,2), padding=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=(hidden_channels *2) * (7*7),\n",
        "                             out_features = num_hiddens, bias=False)\n",
        "        self.fc2= nn.Linear(in_features=num_hiddens, out_features=num_classes, bias=False)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.activation(self.conv2(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# for CIFAR10\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self, name, in_channels, hidden_channels, num_hiddens, num_classes):\n",
        "        super(CNN2, self).__init__()\n",
        "        self.name = name\n",
        "        self.activation = nn.ReLU(True)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=hidden_channels, kernel_size=(5, 5), padding=1, stride=1, bias=False)\n",
        "        self.conv2 = nn.Conv2d(in_channels=hidden_channels, out_channels=hidden_channels * 2, kernel_size=(5, 5), padding=1, stride=1, bias=False)\n",
        "        \n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), padding=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=(hidden_channels * 2) * (8 * 8), out_features=num_hiddens, bias=False)\n",
        "        self.fc2 = nn.Linear(in_features=num_hiddens, out_features=num_classes, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.activation(self.conv2(x))\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.flatten(x)\n",
        "    \n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x        "
      ],
      "metadata": {
        "id": "rInPF3k7zz-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#server.py\n",
        "\n",
        "import copy\n",
        "import gc\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from multiprocessing import pool, cpu_count\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "from .models import *\n",
        "from .utils import *\n",
        "from .client import Client\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#연합학습의 전체 프로세스를 조율하는 센터 서버 구현을 위한 클래스\n",
        "#처음에 중앙서버는 모델 골격을 모든 참여 클라이언트의 구성과함께 배포함\n",
        "#연합학습을 진행하는 동안 센터서버는 클라이언트의 일부를 샘플링하고\n",
        "#로컬에서 업데이트된 매개변수를 수신하여 글로벌 매개변수(모델)로 평균화하여 글로벌 모델에 적용함\n",
        "\n",
        "#다음라운드에서 새로 선택된 고객은 업데이트된 글로벌 모델을 로컬모델로 받게됨\n",
        "\n",
        "\n",
        "#Arribute\n",
        "#clients: 연합학습에 참여하는 클라이언트 인스턴스를 포함하는 목록임\n",
        "#__round: 현재 연합 라운드를 나타내는 Int.\n",
        "#writer: 메트릭 및 글로벌 모델의 손실을 추적하는 summarywriter 인스턴스임\n",
        "#모델: 전역모델에 대한 torch.nn 인스턴스\n",
        "#seed: random seed에 대한 초기값\n",
        "#device: training machine indicator(e.g. \"cpu\", \"cuda\")\n",
        "#mp_flag: \"client_update\" 및 \"client_evaluate\" 방법에 대한 다중처리 사용의 boolean indicator\n",
        "#Boolean : True or Flase\n",
        "#data_path: 데이터를 읽는 경로\n",
        "#dataset_name: 데이터셋트의 이름\n",
        "#shards: 파편수\n",
        "#num_shards: non-iid 데이터 분할 시뮬레이션을 위한 샤드수('iid=False'인 경우에만 유효함)\n",
        "#iid 데이터세트(IID or non-iid)를 분할하는 방법을 나타내는 boolean 표시기\n",
        "#init_config: 모델초기화를 위한 kwargs\n",
        "#fraction: 각 연합 라운드에서 선택된 클라이언트 수의 비율임\n",
        "#num_clients: 총 참여 클라이언트 수(local model)\n",
        "#local_epochs: 클라이언트 모델업데이트에 필요한 epoch\n",
        "#batch_size: 클라이언트/글로벌 모델을 업데이트/평가하기 위한 배치크기임\n",
        "#criterion: loss계산을 위한 torch.nn instance\n",
        "#optimzer: 매개변수 업데이트를 위한 torch.optim instance\n",
        "#optim_config: 옵티마이저를 위해 제공되는 kwargs\n",
        "#python *args, **kwargs 의미와 예제\n",
        "# *args: arguments 여러개의 인수를 함수로 받을 때 사용하는 표시임 (튜플형태)\n",
        "# **kwargs : keyword argument 키워드 인수를 받을 때 사용하는 표시임 (딕셔너리 형태) {'키워드':'특정 값}\n",
        "#함수의 파라미터순서: 일반 변수, *변수, **변수\n",
        "#*변수 --> 여러개가 아규먼트로 들어올떄, 함수내부에서는 해당변수를 '튜플'로 처리함\n",
        "#**변수 --> 키워드=''로 입력할 경우에 그것을 각각 키와 값으로 가져오는 '딕셔너리'로 처리함\n",
        "\n",
        "class Server(object):\n",
        "    def __init__(self, writier, model_config={}, global_config={}, data_config={}, init_config={},\n",
        "                 fed_config={}, optim_config={}):\n",
        "        self.clients = None\n",
        "        self._round = 0\n",
        "        self.writer =writer\n",
        "\n",
        "        self.model = eval(model_config[\"name\"])(**model_config)\n",
        "\n",
        "        self.seed = global_config[\"seed\"]\n",
        "        self.device = global_config[\"device\"]\n",
        "        self.mp_flag = global_config[\"is_mp\"]\n",
        "\n",
        "        self.data_path = data_config[\"data_path\"]\n",
        "        self.dataset_name = data_config[\"dataset_name\"]\n",
        "        self.num_shards = data_config[\"num_shards\"]\n",
        "        self.iid = data_config[\"iid\"]\n",
        "\n",
        "        self.init_config = init_config\n",
        "\n",
        "        self.fraction = fed_config[\"C\"]\n",
        "        self.num_clients = fed_config[\"k\"]\n",
        "        self.num_rounds = fed_config[\"R\"]\n",
        "        self.local_epochs = fed_config[\"E\"]\n",
        "        self.batch_size = fed_config[\"B\"]\n",
        "\n",
        "        self.criterion = fed_config[\"criterion\"]\n",
        "        self.optimizer = fed_config[\"optimizer\"]\n",
        "        self.optim_config = optim_config\n",
        "\n",
        "    def setup(self, **init_kwargs):\n",
        "      #연합학습을 위한 모든 구성요소를 설정함\n",
        "      #첫 번째 라운드 이전에만 유효함(초기값)\n",
        "      assert self._round == 0\n",
        "\n",
        "      #모델의 초기 값 weights\n",
        "      torch.manual_seed(self.seed)\n",
        "      init_net(self.model, **self.init_config)\n",
        "\n",
        "      message = f\"[Round: {str(self._round).zfill(4)}] ...successfully initialized model (# parameters: {str(sum(p.numel() for p in self.model.parameters()))})!\"\n",
        "      print(message); logging.info(message)\n",
        "      del message; gc.collect()\n",
        "\n",
        "      #각클라이언트에 대한 로컬 데이터 세트 분할 \n",
        "      local_datasets, test_dataset = create_datasets(self.data_path, self.dataset_name,\n",
        "                                                     self.num_clients, self.num_shards, self.iid)\n",
        "      \n",
        "      # 각 클라이언트에 데이터셋 할당\n",
        "      self.clients = self.create_clients(local_datasets)\n",
        "\n",
        "      #평가를 위한 홀드아웃 데이터 세트 준비\n",
        "      #홀드아웃 데이터는 학습에 사용하지 않은 데이터에 대한 모델의 일반화 능력을 평가하는 데 도움\n",
        "      self.data = test_Dataset\n",
        "      self.dataloader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "      # 클라이언트 업데이트에 대한 세부 설정을 구성하고\n",
        "      self.setup_clients(batch_size = self.batch_size,\n",
        "                         criterion=serlf.criterion, num_local_epochs=self.local_epochs,\n",
        "                         optimizer = self.optimizer, optim_config = self.optim_config)\n",
        "      \n",
        "      #모델 스켈레톤을 모든 클라이언트에게 보냄\n",
        "      self.transmit_model()\n",
        "\n",
        "      #각 클라이언트 인스턴스를 초기화함\n",
        "      def create_clients(self, local_datasets):\n",
        "          clients = [ ]\n",
        "          for k, dataset in tqdm(enumerate(local_datasets), leave=False):\n",
        "              cleint = Client(client_id=k, local_data=dataset, device=self.device)\n",
        "              clients.append(client)\n",
        "\n",
        "          message = f\"[Round: {str(self._round_.zfill(4)}] ... succefully created all {str(self.num_clients)} clients!\"\n",
        "          print(message); logging.info(message)\n",
        "          del message; gc.collect()\n",
        "          return clients\n",
        "      \n",
        "      #각 클라이언트를 설정함\n",
        "      def setup_clients(self, **client_config):\n",
        "          for k, client in tqdm(enumerate(self.clients), leave=False):\n",
        "              client.setup(**client_config)\n",
        "\n",
        "         message = f\"[Round: {str(self._round).zfill(4)}] ...successfully finished setup of all {str(self.num_clients)} clients!\"\n",
        "        print(message); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "      #업데이트된 글로벌 모델을 선택한/모든 클라이언트에게 전송함\n",
        "      def transmit_model(self, sampled_client_indices=None):\n",
        "          #첫번째 연합라운드 이전과 마지막 연합 라운드 이후에 모든 클라이언트에게 글로벌 모델을 보냄\n",
        "          if sampled_client_indicies is None:\n",
        "\n",
        "              assert (self._round == 0) or (self.round == self.num_rounds)\n",
        "\n",
        "              for client in tqdum(self.clients, leave=False):\n",
        "                  client.model = copy.deepcopy(self.model)\n",
        "\n",
        "            message = f\"[Round: {str(self._round).zfill(4)}] ...successfully transmitted models to all {str(self.num_clients)} clients!\"\n",
        "            print(message); logging.info(message)\n",
        "            del message; gc.collect()\n",
        "        else:\n",
        "          #선택한 클라이언트에게 글로벌 모델을 보냄\n",
        "          assert self._round != 0\n",
        "\n",
        "          for idx in tqdm(sampled_client_indices, leave=False):\n",
        "              self.clients[idx].model = copy.deepcopy(self.model)\n",
        "\n",
        "            message = f\"[Round: {str(self._round).zfill(4)}] ...successfully transmitted models to {str(len(sampled_client_indices))} selected clients!\"\n",
        "            print(message); logging.info(message)\n",
        "            del message; gc.collect()\n",
        "\n",
        "        #전체 클라이언트 중 일부를 선택함\n",
        "        # 무작위로 샘플 클라이언트\n",
        "      def sample_clients(self):\n",
        "            message = f\"[Round: {str(self._round).zfill(4)}] Select clients...!\"\n",
        "            print(message); logging.info(message)\n",
        "            del message; gc.collect()\n",
        "\n",
        "        num_sampled_clients = max(int(self.fraction * self.num_clients), 1)\n",
        "        sampled_client_indices = sorted(np.random.choice(a=[i for i in range(self.num_clients)], size=num_sampled_clients, replace=False).tolist())\n",
        "\n",
        "        return sampled_client_indices\n",
        "\n",
        "        #선택한 각 클라이언트의 client updat함수를 호출함\n",
        "        #선택된 클라이언트 업데이트\n",
        "           \n",
        "      def update_selected_clients(self, sampled_client_indices):\n",
        "\n",
        "          message = f\"[Round: {str(self._round).zfill(4)}] Start updating selected {len(sampled_client_indices)} clients...!\"\n",
        "          print(message); logging.info(message)\n",
        "          del message; gc.collect()\n",
        "\n",
        "          selected_total_size = 0\n",
        "          for idx in tqdm(sampled_client_indices, leave=False):\n",
        "            self.clients[idx].client_update()\n",
        "            selected_total_size += len(self.clients[idx])\n",
        "\n",
        "          message = f\"[Round: {str(self._round).zfill(4)}] ...{len(sampled_client_indices)} clients are selected and updated (with total sample size: {str(selected_total_size)})!\"\n",
        "          print(message); logging.info(message)\n",
        "          del message; gc.collect()\n",
        "\n",
        "          return selected_total_size\n",
        "\n",
        "          #선정된 클라이언트 업데이트 방식의 멀티프로세싱 적용 버전임\n",
        "          #선택한 클라이언트 업데이트\n",
        "\n",
        "    def mp_update_selected_clients(self, selected_index):\n",
        "\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] Start updating selected client {str(self.clients[selected_index].id).zfill(4)}...!\"\n",
        "        print(message, flush=True); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "        self.clients[selected_index].client_update()\n",
        "        client_size = len(self.clients[selected_index])\n",
        "\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] ...client {str(self.clients[selected_index].id).zfill(4)} is selected and updated (with total sample size: {str(client_size)})!\"\n",
        "        print(message, flush=True); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "        return client_size\n",
        "        \n",
        "      #선택한 각 클라이언트에서 업데이트 및 전송된 매개변수의 평균\n",
        "    def average_model(self, sampled_client_indices, coefficients):\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] Aggregate updated weights of {len(sampled_client_indices)} clients...!\"\n",
        "        print(message); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "        averaged_weights = OrderedDict()\n",
        "        for it, idx in tqdm(enumerate(sampled_client_indices), leave=False):\n",
        "            local_weights = self.clients[idx].model.state_dict()\n",
        "            for key in self.model.state_dict().keys():\n",
        "                if it == 0:\n",
        "                    averaged_weights[key] = coefficients[it] * local_weights[key]\n",
        "                else:\n",
        "                    averaged_weights[key] += coefficients[it] * local_weights[key]\n",
        "        self.model.load_state_dict(averaged_weights)\n",
        "\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] ...updated weights of {len(sampled_client_indices)} clients are successfully averaged!\"\n",
        "        print(message); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "    \n",
        "    #선택한 각 클라이언트의 \"client_evaluate\" 함수를 호출함\n",
        "    def evaluate_selected_models(self, sampled_client_indices):\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] Evaluate selected {str(len(sampled_client_indices))} clients' models...!\"\n",
        "        print(message); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "        for idx in sampled_client_indices:\n",
        "            self.clients[idx].client_evaluate()\n",
        "\n",
        "        message = f\"[Round: {str(self._round).zfill(4)}] ...finished evaluation of {str(len(sampled_client_indices))} selected clients!\"\n",
        "        print(message); logging.info(message)\n",
        "        del message; gc.collect()\n",
        "\n",
        "    #evaluate 선정된 모델 방식의 멀티프로세싱 적용 버전임\n",
        "    def mp_evaluate_selected_models(self, selected_index):\n",
        "        self.clients[selected_index].client_evaluate()\n",
        "        return True\n",
        "\n",
        "\n",
        "    #연합 훈련을 함\n",
        "    #클라이언트의 미리 정의된 부분을 임의로 선택함\n",
        "    def train_federated_model(self):\n",
        "        sampled_client_indices = self.sample_clients()\n",
        "\n",
        "        #선택한 클라이언트에게 글로벌 모델을 보냄\n",
        "        self.transmit_model(sampled_client_indices)\n",
        "\n",
        "        #로컬 데이터 세트로 선택한 클라이언트를 업데이트함\n",
        "        if self.mp_flag:\n",
        "            with pool.ThreadPool(processes=cpu_count() - 1) as workhorse:\n",
        "                selected_total_size = workhorse.map(self.mp_update_selected_clients, sampled_client_indices)\n",
        "            selected_total_size = sum(selected_total_size)\n",
        "        else:\n",
        "            selected_total_size = self.update_selected_clients(sampled_client_indices)\n",
        "\n",
        "        #로컬 데이터 세트로 선택한 클라이언트 평가(로컬 업데이트에 사용된 것과 동일)\n",
        "        if self.mp_flag:\n",
        "            message = f\"[Round: {str(self._round).zfill(4)}] Evaluate selected {str(len(sampled_client_indices))} clients' models...!\"\n",
        "            print(message); logging.info(message)\n",
        "            del message; gc.collect()\n",
        "\n",
        "            with pool.ThreadPool(processes=cpu_count() - 1) as workhorse:\n",
        "                workhorse.map(self.mp_evaluate_selected_models, sampled_client_indices)\n",
        "        else:\n",
        "            self.evaluate_selected_models(sampled_client_indices)\n",
        "\n",
        "        #가중치의 평균 계수 계산\n",
        "        mixing_coefficients = [len(self.clients[idx]) / selected_total_size for idx in sampled_client_indices]\n",
        "\n",
        "        #선택한 클라이언트의 업데이트된 각 모델 매개변수의 평균을 내고 전역 모델을 업데이트 함\n",
        "        self.average_model(sampled_client_indices, mixing_coefficients)\n",
        "    #\"\"\"글로벌 홀드아웃 데이터 세트(self.data)를 사용하여 글로벌 모델을 평가합니다.\"\"\"    \n",
        "    def evaluate_global_model(self):\n",
        "        self.model.eval()\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        test_loss, correct = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data, labels in self.dataloader:\n",
        "                data, labels = data.float().to(self.device), labels.long().to(self.device)\n",
        "                outputs = self.model(data)\n",
        "                test_loss += eval(self.criterion)()(outputs, labels).item()\n",
        "                \n",
        "                predicted = outputs.argmax(dim=1, keepdim=True)\n",
        "                correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
        "                \n",
        "                if self.device == \"cuda\": torch.cuda.empty_cache()\n",
        "        self.model.to(\"cpu\")\n",
        "\n",
        "        test_loss = test_loss / len(self.dataloader)\n",
        "        test_accuracy = correct / len(self.data)\n",
        "        return test_loss, test_accuracy\n",
        "\n",
        "    \"\"\"연합 학습의 전 과정을 실행합니다.\"\"\"\n",
        "    def fit(self):\n",
        "        self.results = {\"loss\": [], \"accuracy\": []}\n",
        "        for r in range(self.num_rounds):\n",
        "            self._round = r + 1\n",
        "            \n",
        "            self.train_federated_model()\n",
        "            test_loss, test_accuracy = self.evaluate_global_model()\n",
        "            \n",
        "            self.results['loss'].append(test_loss)\n",
        "            self.results['accuracy'].append(test_accuracy)\n",
        "\n",
        "            self.writer.add_scalars(\n",
        "                'Loss',\n",
        "                {f\"[{self.dataset_name}]_{self.model.name} C_{self.fraction}, E_{self.local_epochs}, B_{self.batch_size}, IID_{self.iid}\": test_loss},\n",
        "                self._round\n",
        "                )\n",
        "            self.writer.add_scalars(\n",
        "                'Accuracy', \n",
        "                {f\"[{self.dataset_name}]_{self.model.name} C_{self.fraction}, E_{self.local_epochs}, B_{self.batch_size}, IID_{self.iid}\": test_accuracy},\n",
        "                self._round\n",
        "                )\n",
        "\n",
        "            message = f\"[Round: {str(self._round).zfill(4)}] Evaluate global model's performance...!\\\n",
        "                \\n\\t[Server] ...finished evaluation!\\\n",
        "                \\n\\t=> Loss: {test_loss:.4f}\\\n",
        "                \\n\\t=> Accuracy: {100. * test_accuracy:.2f}%\\n\"            \n",
        "            print(message); logging.info(message)\n",
        "            del message; gc.collect()\n",
        "        self.transmit_model()"
      ],
      "metadata": {
        "id": "_Zw1mNWH3bxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#utils.py\n",
        "\n",
        "\n",
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init ##??\n",
        "\n",
        "from torch.utils.data import Dataset, TensorDataset, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "#######################\n",
        "# TensorBaord setting #\n",
        "#######################\n",
        "def launch_tensor_board(log_path, port, host):\n",
        "    #Tensor Board를 초기화하는 기능임 \n",
        "    \n",
        "    #인수\n",
        "        #log_path: 로그가 저장되는 경로\n",
        "        #port : TensorBoard를 시작하는데 사용되는 포트번호임\n",
        "        #host: TensorBoard를 시작하는데 사용되는 주소임\n",
        "\n",
        "  \n",
        "    os.system(f\"tensorboard --logdir={log_path} --port={port} --host={host}\")\n",
        "    return True\n",
        "\n",
        "#########################\n",
        "# Weight initialization #\n",
        "#########################\n",
        "\n",
        "#가중치 초기화\n",
        "\n",
        "def init_weights(model, init_type, init_gain):\n",
        "    #네트워크 가중치를 초기화하는 기능임\n",
        "    \n",
        "    #인수:\n",
        "        #모델:초기화할 torch.nn 인스턴스\n",
        "        #init_type: 초기화 방법의 이름(normal | xavier | kaiming | orthogonal).\n",
        "        #init_gain: (normal | xavier | orthogonal)에 대한 배율 인수.\n",
        "    \n",
        "    #Reference:\n",
        "        #https://github.com/DS3Lab/forest-prediction/blob/master/pix2pix/models/networks.py\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            else:\n",
        "                raise NotImplementedError(f'[ERROR] ...initialization method [{init_type}] is not implemented!')\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        \n",
        "        elif classname.find('BatchNorm2d') != -1 or classname.find('InstanceNorm2d') != -1:\n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)   \n",
        "    model.apply(init_func)\n",
        "\n",
        "def init_net(model, init_type, init_gain, gpu_ids):\n",
        "    #네트워크 가중치를 초기화하는 기능임\n",
        "    \n",
        "    #인수:\n",
        "        #모델:초기화할 torch.nn.Module\n",
        "        #init_type: 초기화 방법의 이름(normal | xavier | kaiming | orthogonal)l\n",
        "        #init_gain: (normal | xavier | orthogonal)에 대한 배율 인수.\n",
        "        #gpu_ids: 네트워크가 실행되는 GPU를 나타내는 목록 또는 정수. (예: [0, 1, 2], 0)\n",
        "    \n",
        "    #Returns:\n",
        "        #초기화된 torch.nn.Module 인스턴스.\n",
        "\n",
        "    if len(gpu_ids) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        model.to(gpu_ids[0])\n",
        "        model = nn.DataParallel(model, gpu_ids)\n",
        "    init_weights(model, init_type, init_gain)\n",
        "    return model\n",
        "\n",
        "#################\n",
        "# Dataset split #\n",
        "#################\n",
        "class CustomTensorDataset(Dataset):\n",
        "    #변환을 지원하는 TensorDataset\n",
        "    def __init__(self, tensors, transform=None):\n",
        "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
        "        self.tensors = tensors\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.tensors[0][index]\n",
        "        y = self.tensors[1][index]\n",
        "        if self.transform:\n",
        "            x = self.transform(x.numpy().astype(np.uint8))\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.tensors[0].size(0)\n",
        "\n",
        "def create_datasets(data_path, dataset_name, num_clients, num_shards, iid):\n",
        "    #클라이언트에 배포하기 위해 전체 데이터 세트를 IID 또는 비 IID 방식으로 분할합니다.\"\"\"\n",
        "    dataset_name = dataset_name.upper()\n",
        "    ## 존재하는 경우 torchvision.datasets에서 데이터 세트 가져오기\n",
        "    if hasattr(torchvision.datasets, dataset_name):\n",
        "        ## 데이터 세트마다 변형을 다르게 설정\n",
        "        if dataset_name in [\"CIFAR10\"]:\n",
        "            transform = torchvision.transforms.Compose(\n",
        "                [\n",
        "                    torchvision.transforms.ToTensor(),\n",
        "                    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                ]\n",
        "            )\n",
        "        elif dataset_name in [\"MNIST\"]:\n",
        "            transform = torchvision.transforms.ToTensor()\n",
        "\n",
        "        # prepare raw training & test datasets\n",
        "        training_dataset = torchvision.datasets.__dict__[dataset_name](\n",
        "            root=data_path,\n",
        "            train=True,\n",
        "            download=True,\n",
        "            transform=transform\n",
        "        )\n",
        "        test_dataset = torchvision.datasets.__dict__[dataset_name](\n",
        "            root=data_path,\n",
        "            train=False,\n",
        "            download=True,\n",
        "            transform=transform\n",
        "        )\n",
        "    else:\n",
        "        # 데이터세트를 찾을 수 없음 예외\n",
        "        error_message = f\"...dataset \\\"{dataset_name}\\\" is not supported or cannot be found in TorchVision Datasets!\"\n",
        "        raise AttributeError(error_message)\n",
        "\n",
        "    # 그레이스케일 이미지 데이터셋을 위한 unsqueeze 채널 차원\n",
        "    if training_dataset.data.ndim == 3: # convert to NxHxW -> NxHxWx1 # NxHxW -> NxHxWx1로 변환\n",
        "        training_dataset.data.unsqueeze_(3)\n",
        "    num_categories = np.unique(training_dataset.targets).shape[0]\n",
        "    \n",
        "    if \"ndarray\" not in str(type(training_dataset.data)):\n",
        "        training_dataset.data = np.asarray(training_dataset.data)\n",
        "    if \"list\" not in str(type(training_dataset.targets)):\n",
        "        training_dataset.targets = training_dataset.targets.tolist()\n",
        "    \n",
        "    # iid 플래그에 따라 데이터셋 분할\n",
        "    if iid:\n",
        "        # 데이터 섞기\n",
        "        shuffled_indices = torch.randperm(len(training_dataset))\n",
        "        training_inputs = training_dataset.data[shuffled_indices]\n",
        "        training_labels = torch.Tensor(training_dataset.targets)[shuffled_indices]\n",
        "\n",
        "        # 데이터를 num_clients로 분할\n",
        "        split_size = len(training_dataset) // num_clients\n",
        "        split_datasets = list(\n",
        "            zip(\n",
        "                torch.split(torch.Tensor(training_inputs), split_size),\n",
        "                torch.split(torch.Tensor(training_labels), split_size)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # 로컬 데이터 세트 묶음을 마무리합니다.\n",
        "        local_datasets = [\n",
        "            CustomTensorDataset(local_dataset, transform=transform)\n",
        "            for local_dataset in split_datasets\n",
        "            ]\n",
        "    else:\n",
        "        # 레이블로 데이터 정렬\n",
        "        sorted_indices = torch.argsort(torch.Tensor(training_dataset.targets))\n",
        "        training_inputs = training_dataset.data[sorted_indices]\n",
        "        training_labels = torch.Tensor(training_dataset.targets)[sorted_indices]\n",
        "\n",
        "        # 먼저 데이터를 샤드로 분할\n",
        "        shard_size = len(training_dataset) // num_shards #300\n",
        "        shard_inputs = list(torch.split(torch.Tensor(training_inputs), shard_size))\n",
        "        shard_labels = list(torch.split(torch.Tensor(training_labels), shard_size))\n",
        "\n",
        "        # 목록을 정렬하여 두 개 이상의 클래스에서 각 클라이언트에 샘플을 편리하게 할당\n",
        "        shard_inputs_sorted, shard_labels_sorted = [], []\n",
        "        for i in range(num_shards // num_categories):\n",
        "            for j in range(0, ((num_shards // num_categories) * num_categories), (num_shards // num_categories)):\n",
        "                shard_inputs_sorted.append(shard_inputs[i + j])\n",
        "                shard_labels_sorted.append(shard_labels[i + j])\n",
        "                \n",
        "        # 각 클라이언트에 샤드를 할당하여 로컬 데이터 세트를 마무리합니다.\n",
        "        shards_per_clients = num_shards // num_clients\n",
        "        local_datasets = [\n",
        "            CustomTensorDataset(\n",
        "                (\n",
        "                    torch.cat(shard_inputs_sorted[i:i + shards_per_clients]),\n",
        "                    torch.cat(shard_labels_sorted[i:i + shards_per_clients]).long()\n",
        "                ),\n",
        "                transform=transform\n",
        "            ) \n",
        "            for i in range(0, len(shard_inputs_sorted), shards_per_clients)\n",
        "        ]\n",
        "    return local_datasets, test_dataset"
      ],
      "metadata": {
        "id": "z7e-U2WQeCy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main.py\n",
        "\n",
        "import os #?\n",
        "import time #?\n",
        "import datetime #?\n",
        "import pickle #?\n",
        "import yaml #?\n",
        "import threading #?\n",
        "import logging #?\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from src.server import Server\n",
        "from src.utils import launch_tensor_board\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # read configuration file(yaml file)\n",
        "    with open('./config.yaml') as c:\n",
        "        configs = list(yaml.load_all(c, Loader=yaml.FullLoader))\n",
        "    global_config = configs[0][\"global_config\"]\n",
        "    data_config = configs[1][\"data_config\"]\n",
        "    fed_config = configs[2][\"fed_config\"]\n",
        "    optim_config = configs[3][\"optim_config\"]\n",
        "    init_config = configs[4][\"init_config\"]\n",
        "    model_config = configs[5][\"model_config\"]\n",
        "    log_config = configs[6][\"log_config\"]\n",
        "\n",
        "    #현재시간을 포함하도록 log_path 수정\n",
        "    log_config[\"log_path\"] = os.path.join(log_config[\"log_path\"],\n",
        "                                          str(datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")))\n",
        "\n",
        "    #손실 및 메트릭 추적을 위해 TensorBoard 시작\n",
        "    writer = SummaryWriter(log_dir=log_config[\"log_path\"], filename_suffix=\"FL\")\n",
        "    tb_thread = threading.Thread(target=launch_tensor_board,\n",
        "                                 args=([log_config[\"log_path\"], log_config[\"tb_port\"], log_config[\"tb_host\"]])\n",
        "                                 ).start()\n",
        "    time.sleep(3.0)\n",
        "\n",
        "    #글로벌 logger의 구성 설정\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logging.basicConfig(\n",
        "        filename=os.path.join(log_config[\"log_path\"], log_config[\"log_name\"]),\n",
        "        level = logging.INFO,\n",
        "        fromat = \"[%(levelname)s]($(asctime)s) %(message)s\",\n",
        "        datefmt = \"%Y/%m/%d/ %I:%M:%S %p\")\n",
        "    \n",
        "    #디스플레이 및 로그실험 구성\n",
        "    message = \"\\n[WELCOME] Unfolding configurations...!\"\n",
        "    print(message); logging.info(message)    \n",
        "\n",
        "    for config in configs:\n",
        "        print(config); logging.info(config)\n",
        "    print()\n",
        "\n",
        "    #연합학습 초기화\n",
        "    central_server = Server(writer, model_config, global_config, data_config, init_config,\n",
        "                            fed_config, optim_config)\n",
        "    central_server.setup()\n",
        "\n",
        "    #do federated learning\n",
        "    central_sever.fit()\n",
        "\n",
        "    #save resulting losses and metrics\n",
        "    with open(os.path.join(log_config[\"log_path\"], \"result.pkl\"), \"wb\") as f:\n",
        "        picke.dump(central_server.results, f)\n",
        "\n",
        "    # bye !\n",
        "    message = \"...done all learning process!\\n...exit program!\"\n",
        "    print(message); logging.info(message)\n",
        "    time.sleep(3); exit()"
      ],
      "metadata": {
        "id": "1huW21utioxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
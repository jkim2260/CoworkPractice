{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281e8a479e56679c452a8d5a0a64bf75082165a5\n",
      "ba44182af395af67f5157d40a15c49024f0b74a4\n",
      "dab2e4d8af18612a6b957e9adde14fc0b7d0a33d\n",
      "e5434937229322b1ec7f633956ff572b16226d88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiate\\anaconda3\\envs\\FedLearning\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([84096, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 228\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m i_client \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_client):\n\u001b[0;32m    227\u001b[0m     (loss, temp) \u001b[39m=\u001b[39m FLlstm\u001b[39m.\u001b[39mtrain_client(i_client, client, client_ans, training_iter[i_client])\n\u001b[1;32m--> 228\u001b[0m     CVRMSE \u001b[39m=\u001b[39m FLlstm\u001b[39m.\u001b[39;49mpredict_client(i_client, client_test, client_ans_test)\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m i_client \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    230\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(temp)):\n",
      "Cell \u001b[1;32mIn[100], line 173\u001b[0m, in \u001b[0;36mFL_LSTM.predict_client\u001b[1;34m(self, i_client, client_test, client_ans_test)\u001b[0m\n\u001b[0;32m    171\u001b[0m y \u001b[39m=\u001b[39m batch_test\n\u001b[0;32m    172\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels[i_client]:\n\u001b[1;32m--> 173\u001b[0m     y \u001b[39m=\u001b[39m layer(y)             \n\u001b[0;32m    175\u001b[0m target_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(target_test)\n\u001b[0;32m    176\u001b[0m avg_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(target_test)\n",
      "File \u001b[1;32mc:\\Users\\kiate\\anaconda3\\envs\\FedLearning\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kiate\\anaconda3\\envs\\FedLearning\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def copy_state(state):\n",
    "    return {k: v.cpu().clone() for k, v in state.items()}\n",
    "\n",
    "def making_plot(y):\n",
    "    x = []\n",
    "    for i in range(len(y)):\n",
    "        x.append(i)\n",
    "    return x,y\n",
    "\n",
    "def change_data_tensor(data):\n",
    "    new_tensor_data = []\n",
    "    for i in range(len(data)):\n",
    "        tensor_data = torch.Tensor(data[i].values)\n",
    "        new_tensor_data.append(tensor_data)\n",
    "    return new_tensor_data\n",
    "\n",
    "class FedLearningDataLoader(object):\n",
    "    #Loading one building data//min-max regularization//shuffling\n",
    "    def __init__(self, obj_data):\n",
    "        self.data = obj_data\n",
    "        self.data.isnull().sum().sum()\n",
    "        self.data = self.data.dropna()\n",
    "        colnames = self.data.columns\n",
    "        self.data = data.drop([data.columns[0], data.columns[16]], axis =1)\n",
    "        \n",
    "    \n",
    "    #Splitting data by the number of client//training(80%) and test(20%)\n",
    "    def client_data_partition(self):\n",
    "        client = [];client_ans = [];client_test =[];client_ans_test=[]\n",
    "\n",
    "        #########modify#########\n",
    "        groups = self.data.groupby(\"Identifier\")\n",
    "        temp_result = dict(list(groups))\n",
    "        for key in temp_result.keys():\n",
    "            print(key)\n",
    "        \n",
    "        client_temp = []; client_ans_temp = []\n",
    "        for v in temp_result.values():\n",
    "            v = pd.DataFrame(v)\n",
    "            v = v.drop([v.columns[13]], axis=1)\n",
    "            #v = v.drop([v.columns[2]], axis=1)\n",
    "            colnames = v.columns\n",
    "            MS = MinMaxScaler()\n",
    "            v1 = MS.fit_transform(v)\n",
    "            v1 = pd.DataFrame(v1, columns=colnames)\n",
    "            x_data = v1.iloc[:, :-1]\n",
    "            y_data = v1.iloc[:, [-1]]          \n",
    "            client_temp.append(x_data)\n",
    "            client_ans_temp.append(y_data)\n",
    "\n",
    "        for i in range(len(client_temp)):\n",
    "            client.append(client_temp[i].iloc[:int(len(client_temp[i])*0.8), :])\n",
    "            client_ans.append(client_ans_temp[i].iloc[:int(len(client_ans_temp[i])*0.8), :])\n",
    "            client_test.append(client_temp[i].iloc[int(len(client_temp[i])*0.8):, :])\n",
    "            client_ans_test.append(client_ans_temp[i].iloc[int(len(client_ans_temp[i])*0.8):, :])\n",
    "            \n",
    "        #client = change_data_tensor(client)\n",
    "        #client_ans = change_data_tensor(client_ans)\n",
    "        #client_test = change_data_tensor(client_test)\n",
    "        #client_ans_test = change_data_tensor(client_ans_test)\n",
    "        return client, client_ans, client_test, client_ans_test\n",
    "\n",
    "'''class FedLearningDataLoader(object):\n",
    "    #Loading one building data//min-max regularization//shuffling\n",
    "    def __init__(self, obj_data):\n",
    "        self.data = obj_data\n",
    "        self.data.isnull().sum().sum()\n",
    "        self.data = self.data.dropna()\n",
    "        colnames = self.data.columns\n",
    "        MS = MinMaxScaler()\n",
    "        self.data = MS.fit_transform(self.data)\n",
    "        data = pd.DataFrame(self.data, columns=colnames)\n",
    "        data = shuffle(data)\n",
    "        self.x_data = data.iloc[:, :-1]\n",
    "        self.y_data = data.iloc[:, [-1]]\n",
    "    \n",
    "    #Splitting data by the number of client//training(80%) and test(20%)\n",
    "    def client_data_partition(self, num):\n",
    "        client = [];client_ans = [];client_test =[];client_ans_test=[]\n",
    "        \n",
    "        split_loc = len(self.x_data)//num\n",
    "        for i in range(num):\n",
    "            temp_x = self.x_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
    "            temp_y = self.y_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
    "            \n",
    "            client.append(temp_x.iloc[:int(len(temp_x)*0.8), :])\n",
    "            client_ans.append(temp_y.iloc[:int(len(temp_y)*0.8), :])\n",
    "            client_test.append(temp_x.iloc[int(len(temp_x)*0.8):, :])\n",
    "            client_ans_test.append(temp_y.iloc[int(len(temp_y)*0.8):, :])\n",
    "\n",
    "        return client, client_ans, client_test, client_ans_test'''\n",
    "    \n",
    "class FL_LSTM(nn.Module):\n",
    "    def __init__(self, in_features, out_features, hidden_size, num_layers, seq_length, num_client, learning_rate):\n",
    "        super(FL_LSTM, self).__init__()\n",
    "        self.models = []\n",
    "        self.optimizers = []\n",
    "        self.num_client = num_client\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        for i_client in range(num_client):\n",
    "            self.models.append(\n",
    "                nn.ModuleList([\n",
    "                    nn.LSTM(input_size = in_features, hidden_size = hidden_size, num_layers = num_layers, batch_first = True),\n",
    "                    nn.Linear(hidden_size, out_features)\n",
    "                ])\n",
    "            )\n",
    "            \n",
    "            #self.optimizers.append(torch.optim.SGD(params=self.models[i_client].parameters(), lr=learning_rate, weight_decay=LAMBDA))\n",
    "            self.optimizers.append(torch.optim.Adam(params=self.models[i_client].parameters(), lr=learning_rate))\n",
    "            \n",
    "        self.loss_function = nn.MSELoss()\n",
    "    \n",
    "    ################이부분 수정##################\n",
    "    def train_client(self, i_client, client, client_ans, iteration):\n",
    "        #calculate ith client part w.r.t current weight and bias\n",
    "        temp=[]\n",
    "        for step in range(iteration):\n",
    "            batch_train = torch.from_numpy(pd.DataFrame.to_numpy(client[i_client], dtype=np.float32))\n",
    "            index_target = pd.DataFrame.to_numpy(client_ans[i_client], dtype=np.float32)\n",
    "            \n",
    "            batch_train.requires_grad = True\n",
    "            self.optimizers[i_client].zero_grad()\n",
    "            y = batch_train\n",
    "            \n",
    "            weight, (h_out, c_out) = self.models[i_client][0](y)\n",
    "            h_out = h_out.view(-1, self.hidden_size)\n",
    "            y = self.models[i_client][1](h_out)        \n",
    "            #print('--------hout--------')\n",
    "            #print(h_out)\n",
    "            #print('--------cout--------')\n",
    "            #print(c_out)\n",
    "            #print(y)\n",
    "                \n",
    "            target = torch.from_numpy(index_target)\n",
    "            loss = self.loss_function(y, target)\n",
    "            loss.backward()      \n",
    "            # check gradients\n",
    "            #for layer in self.models[i_client]:\n",
    "            #    grads = [p.grad for p in layer.parameters()]\n",
    "            #    param = [p for p in layer.parameters()]\n",
    "            param = [p for p in self.models[i_client][0].parameters()]\n",
    "            self.optimizers[i_client].step()\n",
    "            \n",
    "            temp.append(loss.item())\n",
    "\n",
    "        loss = loss.detach().numpy()\n",
    "        #print('loss', loss)\n",
    "        #print('------------param------------')\n",
    "        #print(param)     \n",
    "        #print('------------End------------')\n",
    "        return loss, temp\n",
    "    \n",
    "    \n",
    "    #Calculate accuracy of the model(CVRMSE)\n",
    "    def predict_client(self, i_client, client_test, client_ans_test):\n",
    "        batch_test = torch.from_numpy(pd.DataFrame.to_numpy(client_test[i_client], dtype=np.float32))\n",
    "        target_test = pd.DataFrame.to_numpy(client_ans_test[i_client], dtype=np.float32)\n",
    "        \n",
    "        y = batch_test\n",
    "        for layer in self.models[i_client]:\n",
    "            y = layer(y)             \n",
    "    \n",
    "        target_test = torch.from_numpy(target_test)\n",
    "        avg_target = torch.mean(target_test)\n",
    "        CVRMSE = torch.sqrt(self.loss_function(target_test, y))/avg_target * 100\n",
    "        return CVRMSE\n",
    "    \n",
    "    #Aggregate and average weights of all client part\n",
    "    def server_aggregate(self):\n",
    "        #server_aggregate\n",
    "        state_aggregate = None\n",
    "        for model in self.models:\n",
    "            if state_aggregate is None:\n",
    "                state_aggregate = copy_state(model.state_dict())\n",
    "                state_aggregate = model.state_dict()\n",
    "                #print(state_aggregate)\n",
    "            else:\n",
    "                for key, value in model.state_dict().items():\n",
    "                    state_aggregate[key] += value.cpu().clone()       \n",
    "    \n",
    "        for key, value in state_aggregate.items():\n",
    "            state_aggregate[key] /= len(self.models)\n",
    "            #print(state_aggregate[key])  \n",
    "        \n",
    "        # send average model to clinets from server\n",
    "        for model in self.models:\n",
    "            model.load_state_dict(state_aggregate, strict=True)\n",
    "        \n",
    "        #print(model)\n",
    "        return\n",
    "    \n",
    "########################################################\n",
    "#From this, the main code starts\n",
    "########################################################\n",
    "#data = pd.read_csv('C:/Research/cowork/ISE_537_CA_OneBuilding_Part_1.csv') \n",
    "#data = pd.read_csv('C:/Research/cowork/E_Building.csv')\n",
    "data = pd.read_csv('C:/Research/cowork/ISE_537_4Buildings_Final_prac.csv')\n",
    "FLDataset = FedLearningDataLoader(data)\n",
    "\n",
    "#data partitioning <- the number of client is three\n",
    "(client, client_ans, client_test, client_ans_test) = FLDataset.client_data_partition()\n",
    "\n",
    "in_features = client[0].shape[-1]; out_features = 1\n",
    "num_client = 1; learning_rate = 0.05; \n",
    "communication = 1; seq_length = 1; hidden_size = 1; num_layers = 1\n",
    "training_iter = [1, 1, 1, 1]\n",
    "\n",
    "FLlstm = FL_LSTM(in_features, out_features, hidden_size, num_layers, seq_length, num_client, learning_rate)\n",
    "(loss, temp) = FLlstm.train_client(0, client, client_ans, 1)\n",
    "\n",
    "loss_client1 = [];loss_client2 = [];loss_client3 = [];loss_client4 = []  # losses of client loss\n",
    "CVRMSE1=[];CVRMSE2=[];CVRMSE3=[];CVRMSE4=[] # making plot of accuracy trend through increasing the number of communication\n",
    "for i in range(communication):\n",
    "    for i_client in range(num_client):\n",
    "        (loss, temp) = FLlstm.train_client(i_client, client, client_ans, training_iter[i_client])\n",
    "        CVRMSE = FLlstm.predict_client(i_client, client_test, client_ans_test)\n",
    "        if i_client == 0:\n",
    "            for j in range(len(temp)):\n",
    "                loss_client1.append(temp[j])\n",
    "            CVRMSE1.append(CVRMSE.item())\n",
    "        elif i_client == 1:\n",
    "            for j in range(len(temp)):\n",
    "                loss_client2.append(temp[j])\n",
    "            CVRMSE2.append(CVRMSE.item())\n",
    "        elif i_client == 2:\n",
    "            for j in range(len(temp)):\n",
    "                loss_client3.append(temp[j])   \n",
    "            CVRMSE3.append(CVRMSE.item())\n",
    "        elif i_client == 3:\n",
    "            for j in range(len(temp)):\n",
    "                loss_client4.append(temp[j])\n",
    "            CVRMSE4.append(CVRMSE.item())        \n",
    "    # average weight in server and update\n",
    "    FLlstm.server_aggregate()\n",
    "    \n",
    "    # making plot of accuracy trend through increasing the number of communication\n",
    "\n",
    "\n",
    "(x1, loss_client1) = making_plot(loss_client1)\n",
    "(x2, loss_client2) = making_plot(loss_client2)\n",
    "(x3, loss_client3) = making_plot(loss_client3)\n",
    "(x4, loss_client4) = making_plot(loss_client4)\n",
    "(x11, CVRMSE1) = making_plot(CVRMSE1)\n",
    "(x22, CVRMSE2) = making_plot(CVRMSE2)\n",
    "(x33, CVRMSE3) = making_plot(CVRMSE3)\n",
    "(x44, CVRMSE4) = making_plot(CVRMSE4)\n",
    "plt.figure(1)\n",
    "plt.title(\"loss value of each class\")\n",
    "plt.plot(x1, loss_client1, 'b--', label = 'client1')\n",
    "plt.plot(x2, loss_client2, 'r--', label = 'client2')\n",
    "plt.plot(x3, loss_client3, 'g--', label = 'client3')\n",
    "plt.plot(x4, loss_client4, 'k--', label = 'client4')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.title(\"CVRMSE trend of each class\")\n",
    "plt.plot(x11, CVRMSE1, 'b--', label = 'client1')\n",
    "plt.plot(x22, CVRMSE2, 'r--', label = 'client2')\n",
    "plt.plot(x33, CVRMSE3, 'g--', label = 'client3')\n",
    "plt.plot(x44, CVRMSE4, 'k--', label = 'client4')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "for i_client in range(num_client):\n",
    "    CVRMSE = FLlstm.predict_client(i_client, client_test, client_ans_test)\n",
    "    print(\"CVRMSE of client\", i_client, \":\", CVRMSE.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d9c63f866f60b974796075f5c09289b8fc4f57e9d727c901eeb59a008f9ea7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

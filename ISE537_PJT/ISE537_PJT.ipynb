{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple linear regression 's MBE is -0.00026904658327566144\n",
      "multiple linear regression 's NMBE is -0.05084031534297106\n",
      "multiple linear regression 's CVRMSE is 5.751706832407151\n",
      "-----------------------------------\n",
      "Ridge 's MBE is -0.0002671341285841223\n",
      "Ridge 's NMBE is -0.050478928855868285\n",
      "Ridge 's CVRMSE is 5.752854308275889\n",
      "-----------------------------------\n",
      "LASSO 's MBE is 0.0009229872474302257\n",
      "LASSO 's NMBE is 0.17441203729695706\n",
      "LASSO 's CVRMSE is 24.437856126785185\n",
      "-----------------------------------\n",
      "Elastic Net 's MBE is 0.0009229872474302257\n",
      "Elastic Net 's NMBE is 0.17441203729695706\n",
      "Elastic Net 's CVRMSE is 24.437856126785185\n",
      "-----------------------------------\n",
      "LARS 's MBE is -0.0002742196239118413\n",
      "LARS 's NMBE is -0.05181783757731188\n",
      "LARS 's CVRMSE is 5.8337748018446\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiate\\anaconda3\\envs\\FedLearning\\lib\\site-packages\\sklearn\\linear_model\\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\kiate\\anaconda3\\envs\\FedLearning\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP 's MBE is 0.01135950786937041\n",
      "MLP 's NMBE is 2.146546353380124\n",
      "MLP 's CVRMSE is 5.333932381077588\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nx = []\\nfor i in range(len(y_test[:100])):\\n    x.append(i)\\n    \\nplt.plot(x,y_test[:100], 'b',label = 'actual')\\nplt.plot(x,y_pred[:100], 'r--', label = 'predict')\\nplt.legend()\\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import numpy as np\n",
    "import pickle #pickle is used to save the model(python ver.)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm import tqdm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "class ISE(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def data_split(self):\n",
    "        x_data = self.data.iloc[:, :-1]\n",
    "        y_data = self.data.iloc[:, [-1]]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=0)\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, model):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        y_pred = model.predict(self.x_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def evaluation(self, name, y_pred, x_test):\n",
    "        temp_y_test = self.y_test['Thermostat_Temperature']\n",
    "        temp_y_test1 = temp_y_test.values\n",
    "        if name == 'Ridge' or name == 'multiple linear regression':\n",
    "            y_pred1 = pd.Series(y_pred[:,0])\n",
    "            y_pred2 = y_pred1.values    \n",
    "            difference = temp_y_test1 - y_pred2        \n",
    "        else:\n",
    "            difference = temp_y_test1 - y_pred\n",
    "        \n",
    "        ##MBE###\n",
    "        MBE = sum(difference)/len(difference) \n",
    "        print(name, \"'s MBE is\", MBE)\n",
    "        \n",
    "        ##MNBE###\n",
    "        mean = np.mean(temp_y_test)\n",
    "        parameter = len(x_test.axes[1])\n",
    "        NMBE = sum(difference)/(mean*(len(temp_y_test)-parameter)) * 100\n",
    "        print(name, \"'s NMBE is\", NMBE)        \n",
    "        \n",
    "        ###Coefficient of Variation of the Root Mean Square Error(CVRMSE)###\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = math.sqrt(mse)\n",
    "        Avg_target = sum(temp_y_test)/len(temp_y_test)\n",
    "        CVRMSE = rmse/Avg_target * 100\n",
    "        print(name, \"'s CVRMSE is\", CVRMSE)\n",
    "        \n",
    "        ###r2###\n",
    "        #r2_score_ = r2_score(self.x_test, self.y_test)\n",
    "        #print(name, \"'s r2 socre is\", r2_score_)        \n",
    "        return\n",
    "\n",
    "\n",
    "data = pd.read_csv('C:/Research/cowork/ISE_537_CA_OneBuilding_Part_1.csv')\n",
    "data.isnull().sum().sum()\n",
    "data = data.dropna()\n",
    "colnames = data.columns\n",
    "MS = MinMaxScaler()\n",
    "data = MS.fit_transform(data)\n",
    "data = pd.DataFrame(data, columns=colnames)\n",
    "\n",
    "\n",
    "models = []\n",
    "#models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('multiple linear regression', linear_model.LinearRegression()))\n",
    "models.append(('Ridge', Ridge()))\n",
    "models.append(('LASSO', linear_model.Lasso()))\n",
    "models.append(('Elastic Net', ElasticNet()))\n",
    "models.append(('LARS', linear_model.Lars()))\n",
    "models.append(('MLP', MLPRegressor()))\n",
    "\n",
    "ISE = ISE(data)\n",
    "(x_train, x_test, y_train, y_test) = ISE.data_split()\n",
    "for name, model in models:\n",
    "    y_pred = ISE.train(x_train, y_train, x_test, y_test, model)\n",
    "    ISE.evaluation(name, y_pred, x_test)\n",
    "    print(\"-----------------------------------\")\n",
    "\n",
    "'''\n",
    "x = []\n",
    "for i in range(len(y_test[:100])):\n",
    "    x.append(i)\n",
    "    \n",
    "plt.plot(x,y_test[:100], 'b',label = 'actual')\n",
    "plt.plot(x,y_pred[:100], 'r--', label = 'predict')\n",
    "plt.legend()\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d9c63f866f60b974796075f5c09289b8fc4f57e9d727c901eeb59a008f9ea7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

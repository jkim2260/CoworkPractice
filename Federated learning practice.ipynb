{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "90                 5.5               2.6                4.4               1.2\n",
      "109                7.2               3.6                6.1               2.5\n",
      "27                 5.2               3.5                1.5               0.2\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "102                7.1               3.0                5.9               2.1\n",
      "59                 5.2               2.7                3.9               1.4\n",
      "64                 5.6               2.9                3.6               1.3\n",
      "91                 6.1               3.0                4.6               1.4\n",
      "86                 6.7               3.1                4.7               1.5\n",
      "131                7.9               3.8                6.4               2.0\n",
      "104                6.5               3.0                5.8               2.2\n",
      "45                 4.8               3.0                1.4               0.3\n",
      "11                 4.8               3.4                1.6               0.2\n",
      "130                7.4               2.8                6.1               1.9\n",
      "114                5.8               2.8                5.1               2.4\n",
      "97                 6.2               2.9                4.3               1.3\n",
      "14                 5.8               4.0                1.2               0.2\n",
      "57                 4.9               2.4                3.3               1.0\n",
      "84                 5.4               3.0                4.5               1.5\n",
      "44                 5.1               3.8                1.9               0.4\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "137                6.4               3.1                5.5               1.8\n",
      "17                 5.1               3.5                1.4               0.3\n",
      "13                 4.3               3.0                1.1               0.1\n",
      "105                7.6               3.0                6.6               2.1\n",
      "135                7.7               3.0                6.1               2.3\n",
      "95                 5.7               3.0                4.2               1.2\n",
      "31                 5.4               3.4                1.5               0.4\n",
      "112                6.8               3.0                5.5               2.1\n",
      "39                 5.1               3.4                1.5               0.2\n",
      "71                 6.1               2.8                4.0               1.3\n",
      "115                6.4               3.2                5.3               2.3\n",
      "55                 5.7               2.8                4.5               1.3\n",
      "47                 4.6               3.2                1.4               0.2\n",
      "132                6.4               2.8                5.6               2.2\n",
      "85                 6.0               3.4                4.5               1.6\n",
      "118                7.7               2.6                6.9               2.3\n",
      "140                6.7               3.1                5.6               2.4\n",
      "110                6.5               3.2                5.1               2.0\n",
      "61                 5.9               3.0                4.2               1.5      target\n",
      "90        1\n",
      "109       2\n",
      "27        0\n",
      "18        0\n",
      "102       2\n",
      "59        1\n",
      "64        1\n",
      "91        1\n",
      "86        1\n",
      "131       2\n",
      "104       2\n",
      "45        0\n",
      "11        0\n",
      "130       2\n",
      "114       2\n",
      "97        1\n",
      "14        0\n",
      "57        1\n",
      "84        1\n",
      "44        0\n",
      "3         0\n",
      "137       2\n",
      "17        0\n",
      "13        0\n",
      "105       2\n",
      "135       2\n",
      "95        1\n",
      "31        0\n",
      "112       2\n",
      "39        0\n",
      "71        1\n",
      "115       2\n",
      "55        1\n",
      "47        0\n",
      "132       2\n",
      "85        1\n",
      "118       2\n",
      "140       2\n",
      "110       2\n",
      "61        1      sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "70                 5.9               3.2                4.8               1.8\n",
      "144                6.7               3.3                5.7               2.5\n",
      "33                 5.5               4.2                1.4               0.2\n",
      "48                 5.3               3.7                1.5               0.2\n",
      "34                 4.9               3.1                1.5               0.2\n",
      "46                 5.1               3.8                1.6               0.2\n",
      "122                7.7               2.8                6.7               2.0\n",
      "23                 5.1               3.3                1.7               0.5\n",
      "75                 6.6               3.0                4.4               1.4\n",
      "128                6.4               2.8                5.6               2.1      target\n",
      "70        1\n",
      "144       2\n",
      "33        0\n",
      "48        0\n",
      "34        0\n",
      "46        0\n",
      "122       2\n",
      "23        0\n",
      "75        1\n",
      "128       2\n",
      "40 40 10 10\n",
      "[[0.10618485 0.20402631 0.28978885]\n",
      " [0.10434624 0.20179732 0.29385645]\n",
      " [0.1014626  0.20353236 0.29500504]\n",
      " [0.10015034 0.20112866 0.298721  ]] 1.345949752428217\n",
      "[[0.1122069  0.20743198 0.28036112]\n",
      " [0.10860291 0.20327608 0.28812101]\n",
      " [0.10282755 0.20664038 0.29053207]\n",
      " [0.10026986 0.20211522 0.29761492]] 1.295663970865872\n",
      "[[0.11806133 0.21023764 0.27170103]\n",
      " [0.11276771 0.20444869 0.2827836 ]\n",
      " [0.10409121 0.20933425 0.28657454]\n",
      " [0.10035726 0.20296258 0.29668016]] 1.2526532415222869\n",
      "[[0.1237447  0.21247823 0.26377707]\n",
      " [0.11683905 0.20533446 0.27782649]\n",
      " [0.10525086 0.21163486 0.28311429]\n",
      " [0.1004116  0.20367733 0.29591107]] 1.2160595240762024\n",
      "[[0.12925467 0.21419934 0.25654599]\n",
      " [0.12081587 0.20595777 0.27322636]\n",
      " [0.10630457 0.2135713  0.28012414]\n",
      " [0.10043218 0.20426893 0.29529889]] 1.184979696698644\n",
      "[[0.13458976 0.21545328 0.24995696]\n",
      " [0.12469756 0.20634603 0.26895642]\n",
      " [0.10725103 0.21517808 0.27757089]\n",
      " [0.10041852 0.20474876 0.29483271]] 1.1585390438089003\n",
      "[[0.13974915 0.2162953  0.24395555]\n",
      " [0.12848382 0.20652784 0.26498834]\n",
      " [0.10808944 0.2164924  0.27541816]\n",
      " [0.10037031 0.20512922 0.29450047]] 1.1359419253278067\n",
      "[[0.14473256 0.21678056 0.23848689]\n",
      " [0.13217463 0.20653155 0.26129382]\n",
      " [0.10881936 0.21755193 0.27362871]\n",
      " [0.10028737 0.2054229  0.29428973]] 1.1164985452465301\n",
      "[[0.14954016 0.21696192 0.23349792]\n",
      " [0.13577017 0.20638412 0.2578457 ]\n",
      " [0.10944071 0.2183931  0.27216618]\n",
      " [0.10016965 0.20564203 0.29418832]] 1.0996321511962073\n",
      "[[0.15417258 0.21688848 0.22893895]\n",
      " [0.13927086 0.20611052 0.25461862]\n",
      " [0.10995372 0.21905001 0.27099627]\n",
      " [0.10001719 0.20579811 0.2941847 ]] 1.0848730687736876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nLR = LogisticRegression()\\nLR.fit(x_data, y_data.values.ravel())\\ny_pred = LR.predict(x_data)\\nprint(\"LR\\'s Accuracy is\", accuracy_score(y_data, y_pred))\\ncoef = LR.coef_\\nintercept = LR.intercept_\\nprint(coef, intercept)\\n   \\n'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class FedLearning(object):\n",
    "    \n",
    "    #Loading iris data and shuffling for spliting data to clients\n",
    "    def __init__(self, obj_data):\n",
    "        self.data = obj_data        \n",
    "        df = pd.DataFrame(data = self.data.data, columns = self.data.feature_names)\n",
    "        df['target'] = self.data.target\n",
    "        #df['target'] = df['target'].map({0:\"setosa\", 1:\"versicolor\", 2:\"virginica\"})\n",
    "        df = shuffle(df)\n",
    "        self.x_data = df.iloc[:, :-1]\n",
    "        self.y_data = df.iloc[:, [-1]]\n",
    "    \n",
    "    #Spliting data by the number of clients\n",
    "    #Spliting training(80%) and test data(20%) of each client\n",
    "    def client_data(self, num):\n",
    "        client = [];client_ans = [];client_test =[];client_ans_test=[]\n",
    "        split_loc = len(self.x_data)//num\n",
    "        for i in range(num):\n",
    "            temp_x = self.x_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
    "            temp_y = self.y_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
    "            client.append(temp_x.iloc[:int(len(temp_x)*0.8), :])\n",
    "            client_ans.append(temp_y.iloc[:int(len(temp_y)*0.8), :])\n",
    "            client_test.append(temp_x.iloc[int(len(temp_x)*0.8):, :])\n",
    "            client_ans_test.append(temp_y.iloc[int(len(temp_y)*0.8):, :])\n",
    "        return client, client_ans, client_test, client_ans_test\n",
    "    \n",
    "    #initialize weight of model\n",
    "    def weight_ini(self):\n",
    "        #.shape[1] is the number of columns\n",
    "        #.shape[0] is the number of rows\n",
    "        #n_features = self.x_data.shape[1]\n",
    "        #w = np.ones((3,n_features)).T * 0.1\n",
    "        w = np.array([[0.1,0.2,0.3],\n",
    "                      [0.1,0.2,0.3],\n",
    "                      [0.1,0.2,0.3],\n",
    "                      [0.1,0.2,0.3]])\n",
    "        b = np.ones((3,1))                 \n",
    "        return w, b\n",
    "    \n",
    "    #Average weights and bias learned using client data\n",
    "    #client_weight and client_bias are array structure\n",
    "    def server_aggre(self, client_weight, client_bias):\n",
    "        Avg_weight = np.mean(client_weight, axis = 0)\n",
    "        Avg_bias = np.mean(client_bias)\n",
    "        return Avg_weight, Avg_bias\n",
    "    \n",
    "    def client(self, weight, bias, client, client_ans, iteration, learning_rate):\n",
    "        #calculate client data w.r.t current weight and bias\n",
    "        for i in range(iteration):\n",
    "            result = np.matmul(client, weight) #+ bias\n",
    "            \n",
    "            #making probability using the above result\n",
    "            prob_result = self.softmax(result)\n",
    "            prob_result = pd.DataFrame.to_numpy(prob_result.T)\n",
    "            \n",
    "            #making target as numerical data using one hot encoding\n",
    "            client_ans = pd.DataFrame.to_numpy(client_ans)\n",
    "            target = self.one_hot_encoding(client_ans)\n",
    "            \n",
    "            #calculate loss value using cross entropy\n",
    "            loss = self.cross_entropy(target, prob_result)\n",
    "            \n",
    "            #update weight and bias using gradient descent\n",
    "            gradient = self.cost_gradient(target, prob_result, client)\n",
    "            weight = weight - learning_rate * gradient\n",
    "            \n",
    "            prob_result = pd.DataFrame(prob_result)\n",
    "            client_ans = pd.DataFrame(client_ans)\n",
    "            \n",
    "            print(weight, loss)\n",
    "        \n",
    "        return weight, loss\n",
    "        \n",
    "    #I use the multinomial LR model instead of binomial LR\n",
    "    #becasuse the dataset has three classes(multi-class)\n",
    "    #change loss func(log loss to cross-entropy loss)\n",
    "    #and change the sigmoid func to softmax func\n",
    "    def softmax(self, result):\n",
    "        final_result = np.exp(result).T / np.sum(np.exp(result), axis = 1).T\n",
    "        return final_result\n",
    "    \n",
    "    #One hot encoding converts the categorical data into a numerical form\n",
    "    def one_hot_encoding(self, y_data):\n",
    "        OneHotEncoding = []\n",
    "        encoding = []\n",
    "        for i in range(len(y_data)):\n",
    "            if(y_data[i] == 0):\n",
    "                encoding = np.array([1,0,0]) #class 1(setosa)\n",
    "            elif(y_data[i] == 1):\n",
    "                encoding = np.array([0,1,0]) #class 2(versicolor)\n",
    "            elif(y_data[i] == 2):\n",
    "                encoding = np.array([0,0,1]) #class 3(virginica)\n",
    "            OneHotEncoding.append(encoding)\n",
    "        return OneHotEncoding\n",
    "    \n",
    "    #use cross entropy for calculating loss value\n",
    "    def cross_entropy(self, y_data, y_pred):\n",
    "        loss = -np.sum(y_data * np.log(y_pred + 10**-100)) / len(y_data)\n",
    "        return loss\n",
    "    \n",
    "    #use gradient descent for updating weight and bias\n",
    "    def cost_gradient(self, y_data, y_pred, X):\n",
    "        grad = -(np.dot(X.T, (y_data-y_pred))) / len(X)\n",
    "        return grad\n",
    "\n",
    "    \n",
    "\n",
    "iris = load_iris()\n",
    "FL = FedLearning(iris)\n",
    "(client, client_ans, client_test, client_ans_test) = FL.client_data(3)\n",
    "print(client[0], client_ans[0], client_test[0], client_ans_test[0])\n",
    "print(len(client[2]), len(client_ans[2]), len(client_test[2]), len(client_ans_test[2]))\n",
    "(w,b) = FL.weight_ini()\n",
    "#print(client_ans)\n",
    "FL.client(w, b, client[0], client_ans[0], 10, 0.005)\n",
    "\n",
    "'''\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_data, y_data.values.ravel())\n",
    "y_pred = LR.predict(x_data)\n",
    "print(\"LR's Accuracy is\", accuracy_score(y_data, y_pred))\n",
    "coef = LR.coef_\n",
    "intercept = LR.intercept_\n",
    "print(coef, intercept)\n",
    "   \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d9c63f866f60b974796075f5c09289b8fc4f57e9d727c901eeb59a008f9ea7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

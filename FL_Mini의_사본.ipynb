{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mrBaFITkBvLdVKpUNckd2F-LealUMhAQ",
      "authorship_tag": "ABX9TyPL4+WELvAh8pkDItllp1a+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkim2260/CoworkPractice/blob/master/FL_Mini%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5GuJVhOzbeQ",
        "outputId": "41d1d5a4-45bc-4d2b-990e-82f468ed8357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import io\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "def copy_state(state):\n",
        "    return {k: v.cpu().clone() for k, v in state.items()}\n",
        "\n",
        "def making_plot(y):\n",
        "    x = []\n",
        "    for i in range(len(y)):\n",
        "        x.append(i)\n",
        "    return x,y\n",
        "\n",
        "def change_data_tensor(data):\n",
        "    new_tensor_data = []\n",
        "    for i in range(len(data)):\n",
        "        tensor_data = torch.Tensor(data[i].values)\n",
        "        new_tensor_data.append(tensor_data)\n",
        "    return new_tensor_data\n",
        "\n",
        "class FedLearningDataLoader(object):\n",
        "    #Loading one building data//min-max regularization//shuffling\n",
        "    def __init__(self, obj_data):\n",
        "        self.data = obj_data\n",
        "        self.data.isnull().sum().sum()\n",
        "        self.data = self.data.dropna()\n",
        "        colnames = self.data.columns\n",
        "        #self.data = data.drop([data.columns[0], data.columns[16]], axis =1)\n",
        "        self.data = data.drop([data.columns[16]], axis =1) #remove identifier column\n",
        "    \n",
        "    #Splitting data by the number of client//training(80%) and test(20%)\n",
        "    def client_data_partition(self):\n",
        "        client = [];client_ans = [];client_test =[];client_ans_test=[]\n",
        "\n",
        "        #########modify#########\n",
        "        #groups = self.data.groupby(\"Identifier\")\n",
        "        groups = self.data.groupby(\"State\")\n",
        "        temp_result = dict(list(groups))\n",
        "        for key in temp_result.keys():\n",
        "            print(key)\n",
        "        \n",
        "        client_temp = []; client_ans_temp = []\n",
        "        for v in temp_result.values():\n",
        "            v = pd.DataFrame(v)\n",
        "            #v = v.drop([v.columns[13]], axis=1)\n",
        "            #v = v.drop([v.columns[2]], axis=1)\n",
        "            colnames = v.columns\n",
        "            MS = MinMaxScaler()\n",
        "            v1 = MS.fit_transform(v)\n",
        "            v1 = pd.DataFrame(v1, columns=colnames)\n",
        "            x_data = v1.iloc[:, :-1]\n",
        "            y_data = v1.iloc[:, [-1]]          \n",
        "            client_temp.append(x_data)\n",
        "            client_ans_temp.append(y_data)\n",
        "\n",
        "        for i in range(len(client_temp)):\n",
        "            client.append(client_temp[i].iloc[:int(len(client_temp[i])*0.8), :])\n",
        "            client_ans.append(client_ans_temp[i].iloc[:int(len(client_ans_temp[i])*0.8), :])\n",
        "            client_test.append(client_temp[i].iloc[int(len(client_temp[i])*0.8):, :])\n",
        "            client_ans_test.append(client_ans_temp[i].iloc[int(len(client_ans_temp[i])*0.8):, :])\n",
        "            \n",
        "        #client = change_data_tensor(client)\n",
        "        #client_ans = change_data_tensor(client_ans)\n",
        "        #client_test = change_data_tensor(client_test)\n",
        "        #client_ans_test = change_data_tensor(client_ans_test)\n",
        "        return client, client_ans, client_test, client_ans_test\n",
        "\n",
        "'''class FedLearningDataLoader(object):\n",
        "    #Loading one building data//min-max regularization//shuffling\n",
        "    def __init__(self, obj_data):\n",
        "        self.data = obj_data\n",
        "        self.data.isnull().sum().sum()\n",
        "        self.data = self.data.dropna()\n",
        "        colnames = self.data.columns\n",
        "        MS = MinMaxScaler()\n",
        "        self.data = MS.fit_transform(self.data)\n",
        "        data = pd.DataFrame(self.data, columns=colnames)\n",
        "        data = shuffle(data)\n",
        "        self.x_data = data.iloc[:, :-1]\n",
        "        self.y_data = data.iloc[:, [-1]]\n",
        "    \n",
        "    #Splitting data by the number of client//training(80%) and test(20%)\n",
        "    def client_data_partition(self, num):\n",
        "        client = [];client_ans = [];client_test =[];client_ans_test=[]\n",
        "        \n",
        "        split_loc = len(self.x_data)//num\n",
        "        for i in range(num):\n",
        "            temp_x = self.x_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
        "            temp_y = self.y_data.iloc[split_loc*i:split_loc*(i+1), :]\n",
        "            \n",
        "            client.append(temp_x.iloc[:int(len(temp_x)*0.8), :])\n",
        "            client_ans.append(temp_y.iloc[:int(len(temp_y)*0.8), :])\n",
        "            client_test.append(temp_x.iloc[int(len(temp_x)*0.8):, :])\n",
        "            client_ans_test.append(temp_y.iloc[int(len(temp_y)*0.8):, :])\n",
        "        return client, client_ans, client_test, client_ans_test\n",
        "        \n",
        "      def train_client(self, i_client, client, client_ans, iteration):\n",
        "        #calculate ith client part w.r.t current weight and bias\n",
        "        temp=[]\n",
        "        for step in range(iteration):\n",
        "            if step%10 == 0:\n",
        "                print('---------client', i_client, '-----------')\n",
        "            \n",
        "            batch_train = torch.from_numpy(pd.DataFrame.to_numpy(client[i_client], dtype=np.float32))\n",
        "            batch_train = batch_train.cuda()\n",
        "            index_target = pd.DataFrame.to_numpy(client_ans[i_client], dtype=np.float32)\n",
        "            \n",
        "            batch_train.requires_grad = True\n",
        "            self.optimizers[i_client].zero_grad()\n",
        "            y = batch_train\n",
        "            y = y.cuda()\n",
        "            \n",
        "            output, (h_out, c_out) = self.models[i_client][0](y)\n",
        "            #h_out = h_out.view(-1, self.hidden_size)\n",
        "            #y = self.models[i_client][1](h_out)   \n",
        "            y = self.models[i_client][1](output)\n",
        "            target = torch.from_numpy(index_target)\n",
        "            target = target.cuda()\n",
        "            if step%10 == 0:            \n",
        "                print('pred size :', y.shape, 'target size :', target.shape)\n",
        "            \n",
        "            loss = self.loss_function(y, target)\n",
        "            loss.backward()      \n",
        "            \n",
        "            # check gradients\n",
        "            #grads = [p.grad for p in self.models[i_client][0].parameters()]\n",
        "            param = [p for p in self.models[i_client][0].parameters()]\n",
        "            self.optimizers[i_client].step()\n",
        "            \n",
        "            temp.append(loss.item())\n",
        "            if step%10 == 0:\n",
        "                print('iteration: ', step, 'loss: ', loss.item())\n",
        "        loss = loss.cpu().detach().numpy()\n",
        "        #loss = loss.detach().numpy()\n",
        "        #print('loss', loss)\n",
        "        #print('------------param------------')\n",
        "        #print(param)     \n",
        "        #print('------------End------------')\n",
        "        return loss, temp\n",
        "        '''\n",
        "    \n",
        "class FL_LSTM(nn.Module):\n",
        "    def __init__(self, in_features, out_features, hidden_size, num_layers, seq_length, num_client, learning_rate):\n",
        "        super(FL_LSTM, self).__init__()\n",
        "        self.models = []\n",
        "        self.optimizers = []\n",
        "        self.num_client = num_client\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        for i_client in range(num_client):\n",
        "            self.models.append(\n",
        "                nn.ModuleList([\n",
        "                    nn.LSTM(input_size = in_features, hidden_size = hidden_size, num_layers = num_layers, batch_first = True).cuda(),\n",
        "                    nn.Linear(hidden_size, out_features).cuda()\n",
        "                ])\n",
        "            )\n",
        "            \n",
        "            #self.optimizers.append(torch.optim.SGD(params=self.models[i_client].parameters(), lr=learning_rate))\n",
        "            self.optimizers.append(torch.optim.Adam(params=self.models[i_client].parameters(), lr=learning_rate))\n",
        "            \n",
        "        self.loss_function = nn.MSELoss()\n",
        "\n",
        "    def train_client(self, i_client, client, client_ans, iteration):\n",
        "        #calculate ith client part w.r.t current weight and bias\n",
        "        train_loss=[]\n",
        "        for step in range(iteration):\n",
        "            if step == 0:\n",
        "                print('---------client', i_client, '-----------')\n",
        "            \n",
        "            batch_train = torch.from_numpy(pd.DataFrame.to_numpy(client[i_client], dtype=np.float32))\n",
        "            batch_train = batch_train.cuda()\n",
        "            index_target = pd.DataFrame.to_numpy(client_ans[i_client], dtype=np.float32)\n",
        "            target = torch.from_numpy(index_target)\n",
        "            target = target.cuda()\n",
        "\n",
        "            #Training data batch learning\n",
        "            train_data = data_utils.TensorDataset(batch_train, target)\n",
        "            dataloader = data_utils.DataLoader(train_data, batch_size = 262144, shuffle = False) \n",
        "            \n",
        "            #Batch learnining\n",
        "            for idx, (x_batch, y_batch) in enumerate(dataloader):\n",
        "                x_batch.requires_grad = True\n",
        "                self.optimizers[i_client].zero_grad()\n",
        "                #y = batch_train\n",
        "                #y = y.cuda()\n",
        "                \n",
        "                output, (h_out, c_out) = self.models[i_client][0](x_batch)\n",
        "                y_pred = self.models[i_client][1](output)\n",
        "                loss = self.loss_function(y_pred, y_batch)\n",
        "                loss.backward()      \n",
        "            \n",
        "                # check gradients\n",
        "                #grads = [p.grad for p in self.models[i_client][0].parameters()]\n",
        "                param = [p for p in self.models[i_client][0].parameters()]\n",
        "                self.optimizers[i_client].step()\n",
        "            \n",
        "            train_loss.append(loss.item())\n",
        "            print(\"Iteration:{}, Loss_train:{}\".format(step, train_loss[-1]))\n",
        "\n",
        "        loss = loss.cpu().detach().numpy()        \n",
        "        return loss, train_loss    \n",
        "    \n",
        "    #Calculate accuracy of the model(CVRMSE)\n",
        "    def predict_client(self, i_client, client_test, client_ans_test):\n",
        "        batch_test = torch.from_numpy(pd.DataFrame.to_numpy(client_test[i_client], dtype=np.float32))\n",
        "        target_test = pd.DataFrame.to_numpy(client_ans_test[i_client], dtype=np.float32)\n",
        "        \n",
        "        batch_test = batch_test.to(device)\n",
        "        y = batch_test\n",
        "        output, (h_out, c_out) = self.models[i_client][0](y)\n",
        "        #h_out = h_out.view(-1, self.hidden_size)\n",
        "        #y = self.models[i_client][1](h_out)\n",
        "        y = self.models[i_client][1](output)     \n",
        "        y = y.to(device)  \n",
        "    \n",
        "        target_test = torch.from_numpy(target_test)\n",
        "        target_test = target_test.to(device)\n",
        "        avg_target = torch.mean(target_test)\n",
        "        avg_target = avg_target.to(device)\n",
        "        CVRMSE = torch.sqrt(self.loss_function(target_test, y))/avg_target * 100\n",
        "        return CVRMSE\n",
        "    \n",
        "    #Aggregate and average weights of all client part\n",
        "    def server_aggregate(self):\n",
        "        #server_aggregate\n",
        "        state_aggregate = None\n",
        "        for model in self.models:\n",
        "            if state_aggregate is None:\n",
        "                state_aggregate = copy_state(model.state_dict())\n",
        "                state_aggregate = model.state_dict()\n",
        "                #print(state_aggregate)\n",
        "            else:\n",
        "                for key, value in model.state_dict().items():\n",
        "                    state_aggregate[key] += value.cpu().clone().cuda()\n",
        "                    \n",
        "    \n",
        "        for key, value in state_aggregate.items():\n",
        "            state_aggregate[key] /= len(self.models)\n",
        "            #print(state_aggregate[key])  \n",
        "        \n",
        "        # send average model to clinets from server\n",
        "        for model in self.models:\n",
        "            model.load_state_dict(state_aggregate, strict=True)\n",
        "        \n",
        "        #print(model)\n",
        "        return\n",
        "    \n",
        "########################################################\n",
        "#From this, the main code starts\n",
        "########################################################\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "#data = pd.read_csv('C:/Practice/ISE537_PJT/ISE_537_4Buildings_Final.csv')\n",
        "data = pd.read_csv('/content/drive/MyDrive/5_Federated Learning/Data cleaning/0201_FL_FullBldg_data.csv')\n",
        "FLDataset = FedLearningDataLoader(data)\n",
        "\n",
        "\n",
        "#data partitioning <- the number of client is three\n",
        "(client, client_ans, client_test, client_ans_test) = FLDataset.client_data_partition()\n",
        "\n",
        "in_features = client[0].shape[-1]; out_features = 1\n",
        "num_client = 4; learning_rate = 0.05; \n",
        "communication = 20; seq_length = 1; hidden_size = 10; num_layers = 1\n",
        "#training_iter = [60, 30, 50, 15]\n",
        "training_iter = [60, 60, 60, 60]\n",
        "\n",
        "FLlstm = FL_LSTM(in_features, out_features, hidden_size, num_layers, seq_length, num_client, learning_rate)\n",
        "FLlstm.cuda()\n",
        "FLlstm = FLlstm.to(device)\n",
        "\n",
        "\n",
        "loss_client1 = [];loss_client2 = [];loss_client3 = [];loss_client4 = []  # losses of client loss\n",
        "CVRMSE1=[];CVRMSE2=[];CVRMSE3=[];CVRMSE4=[] # making plot of accuracy trend through increasing the number of communication\n",
        "for i in tqdm(range(communication), desc=\"process\", mininterval = 0.01):\n",
        "    time.sleep(0.1)\n",
        "    for i_client in range(num_client):\n",
        "        (loss, temp) = FLlstm.train_client(i_client, client, client_ans, training_iter[i_client])\n",
        "        CVRMSE = FLlstm.predict_client(i_client, client_test, client_ans_test)\n",
        "        if i_client == 0:\n",
        "            for j in range(len(temp)):\n",
        "                loss_client1.append(temp[j])\n",
        "            CVRMSE1.append(CVRMSE.item())\n",
        "        elif i_client == 1:\n",
        "            for j in range(len(temp)):\n",
        "                loss_client2.append(temp[j])\n",
        "            CVRMSE2.append(CVRMSE.item())\n",
        "        elif i_client == 2:\n",
        "            for j in range(len(temp)):\n",
        "                loss_client3.append(temp[j])   \n",
        "            CVRMSE3.append(CVRMSE.item())\n",
        "        elif i_client == 3:\n",
        "            for j in range(len(temp)):\n",
        "                loss_client4.append(temp[j])\n",
        "            CVRMSE4.append(CVRMSE.item())        \n",
        "    # average weight in server and update\n",
        "    print(CVRMSE1[len(CVRMSE1)-1], CVRMSE2[len(CVRMSE2)-1], CVRMSE3[len(CVRMSE3)-1], CVRMSE4[len(CVRMSE4)-1])\n",
        "    if i != communication-1:\n",
        "      FLlstm.server_aggregate()\n",
        "    else:\n",
        "      pass\n",
        "    \n",
        "    # making plot of accuracy trend through increasing the number of communication\n",
        "\n",
        "\n",
        "(x1, loss_client1) = making_plot(loss_client1)\n",
        "(x2, loss_client2) = making_plot(loss_client2)\n",
        "(x3, loss_client3) = making_plot(loss_client3)\n",
        "(x4, loss_client4) = making_plot(loss_client4)\n",
        "(x11, CVRMSE1) = making_plot(CVRMSE1)\n",
        "(x22, CVRMSE2) = making_plot(CVRMSE2)\n",
        "(x33, CVRMSE3) = making_plot(CVRMSE3)\n",
        "(x44, CVRMSE4) = making_plot(CVRMSE4)\n",
        "plt.figure(1)\n",
        "plt.title(\"loss value of each class\")\n",
        "plt.plot(x1, loss_client1, 'b--', label = 'client1')\n",
        "plt.plot(x2, loss_client2, 'r--', label = 'client2')\n",
        "plt.plot(x3, loss_client3, 'g--', label = 'client3')\n",
        "plt.plot(x4, loss_client4, 'k--', label = 'client4')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.title(\"CVRMSE trend of each class\")\n",
        "plt.plot(x11, CVRMSE1, 'b--', label = 'client1')\n",
        "plt.plot(x22, CVRMSE2, 'r--', label = 'client2')\n",
        "plt.plot(x33, CVRMSE3, 'g--', label = 'client3')\n",
        "plt.plot(x44, CVRMSE4, 'k--', label = 'client4')\n",
        "plt.legend()\n",
        "\n",
        "for i_client in range(num_client):\n",
        "    CVRMSE = FLlstm.predict_client(i_client, client_test, client_ans_test)\n",
        "    print(\"CVRMSE of client\", i_client+1, \":\", CVRMSE.item())"
      ]
    }
  ]
}